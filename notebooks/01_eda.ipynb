{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# House Price Prediction - Exploratory Data Analysis\n",
    "\n",
    "**Goal:** Understand the dataset, identify patterns, and prepare for feature engineering\n",
    "\n",
    "**Dataset:** Kaggle House Prices (Ames, Iowa)\n",
    "- Training samples: 1,460\n",
    "- Features: 81\n",
    "- Target: SalePrice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set visualization style\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "\n",
    "print('Libraries imported successfully!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training data\n",
    "train_df = pd.read_csv('../data/raw/train.csv')\n",
    "test_df = pd.read_csv('../data/raw/test.csv')\n",
    "\n",
    "print(f'Training data shape: {train_df.shape}')\n",
    "print(f'Test data shape: {test_df.shape}')\n",
    "print(f'\\nTotal samples: {len(train_df) + len(test_df)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Initial Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display first few rows\n",
    "print('First 5 rows of training data:')\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data info\n",
    "print('Dataset Information:')\n",
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistical summary\n",
    "print('Statistical Summary of Numerical Features:')\n",
    "train_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify data types\n",
    "numerical_features = train_df.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "categorical_features = train_df.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "print(f'Numerical features: {len(numerical_features)}')\n",
    "print(f'Categorical features: {len(categorical_features)}')\n",
    "print(f'\\nNumerical: {numerical_features[:10]} ...')\n",
    "print(f'\\nCategorical: {categorical_features[:10]} ...')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Target Variable Analysis (SalePrice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SalePrice statistics\n",
    "print('SalePrice Statistics:')\n",
    "print(train_df['SalePrice'].describe())\n",
    "print(f'\\nSkewness: {train_df[\"SalePrice\"].skew():.2f}')\n",
    "print(f'Kurtosis: {train_df[\"SalePrice\"].kurtosis():.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize SalePrice distribution\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Histogram\n",
    "axes[0].hist(train_df['SalePrice'], bins=50, edgecolor='black', alpha=0.7)\n",
    "axes[0].set_xlabel('Sale Price ($)', fontsize=12)\n",
    "axes[0].set_ylabel('Frequency', fontsize=12)\n",
    "axes[0].set_title('Distribution of House Prices', fontsize=14, fontweight='bold')\n",
    "axes[0].axvline(train_df['SalePrice'].mean(), color='red', linestyle='--', label=f'Mean: ${train_df[\"SalePrice\"].mean():,.0f}')\n",
    "axes[0].axvline(train_df['SalePrice'].median(), color='green', linestyle='--', label=f'Median: ${train_df[\"SalePrice\"].median():,.0f}')\n",
    "axes[0].legend()\n",
    "\n",
    "# Box plot\n",
    "axes[1].boxplot(train_df['SalePrice'], vert=True)\n",
    "axes[1].set_ylabel('Sale Price ($)', fontsize=12)\n",
    "axes[1].set_title('Box Plot of House Prices', fontsize=14, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f'Price range: ${train_df[\"SalePrice\"].min():,.0f} - ${train_df[\"SalePrice\"].max():,.0f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for normal distribution (Q-Q plot)\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Original SalePrice Q-Q plot\n",
    "stats.probplot(train_df['SalePrice'], dist=\"norm\", plot=axes[0])\n",
    "axes[0].set_title('Q-Q Plot: SalePrice (Original)', fontsize=14, fontweight='bold')\n",
    "\n",
    "# Log-transformed SalePrice Q-Q plot\n",
    "stats.probplot(np.log1p(train_df['SalePrice']), dist=\"norm\", plot=axes[1])\n",
    "axes[1].set_title('Q-Q Plot: SalePrice (Log-Transformed)', fontsize=14, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print('Note: Log transformation may help normalize the target variable for better model performance.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Missing Values Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate missing values\n",
    "missing = train_df.isnull().sum()\n",
    "missing_pct = (missing / len(train_df)) * 100\n",
    "missing_df = pd.DataFrame({\n",
    "    'Feature': missing.index,\n",
    "    'Missing_Count': missing.values,\n",
    "    'Missing_Percentage': missing_pct.values\n",
    "})\n",
    "\n",
    "# Filter features with missing values\n",
    "missing_df = missing_df[missing_df['Missing_Count'] > 0].sort_values('Missing_Percentage', ascending=False)\n",
    "\n",
    "print(f'Features with missing values: {len(missing_df)}/{len(train_df.columns)}')\n",
    "print('\\nTop 10 features with most missing values:')\n",
    "missing_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize missing values\n",
    "if len(missing_df) > 0:\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    top_missing = missing_df.head(15)\n",
    "    plt.barh(top_missing['Feature'], top_missing['Missing_Percentage'], color='coral')\n",
    "    plt.xlabel('Missing Percentage (%)', fontsize=12)\n",
    "    plt.ylabel('Feature', fontsize=12)\n",
    "    plt.title('Top 15 Features with Missing Values', fontsize=14, fontweight='bold')\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print('No missing values found!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Correlation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate correlation with SalePrice\n",
    "correlations = train_df[numerical_features].corr()['SalePrice'].sort_values(ascending=False)\n",
    "\n",
    "print('Top 10 features most correlated with SalePrice:')\n",
    "print(correlations.head(11))  # Include SalePrice itself\n",
    "\n",
    "print('\\nBottom 10 features (least/negatively correlated):')\n",
    "print(correlations.tail(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize top correlations\n",
    "top_features = correlations.head(11).index.tolist()  # Top 10 + SalePrice\n",
    "\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(train_df[top_features].corr(), annot=True, fmt='.2f', \n",
    "            cmap='coolwarm', center=0, square=True, linewidths=1)\n",
    "plt.title('Correlation Heatmap: Top Features vs SalePrice', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bar plot of top correlations\n",
    "top_corr = correlations.head(11)[1:]  # Exclude SalePrice itself\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "top_corr.plot(kind='barh', color='steelblue')\n",
    "plt.xlabel('Correlation with SalePrice', fontsize=12)\n",
    "plt.ylabel('Feature', fontsize=12)\n",
    "plt.title('Top 10 Features Correlated with House Price', fontsize=14, fontweight='bold')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Key Feature Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter plots of top numerical features vs SalePrice\n",
    "top_num_features = correlations.head(6)[1:].index.tolist()  # Top 5 excluding SalePrice\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(16, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, feature in enumerate(top_num_features):\n",
    "    axes[idx].scatter(train_df[feature], train_df['SalePrice'], alpha=0.5)\n",
    "    axes[idx].set_xlabel(feature, fontsize=10)\n",
    "    axes[idx].set_ylabel('SalePrice', fontsize=10)\n",
    "    axes[idx].set_title(f'{feature} vs SalePrice (r={correlations[feature]:.2f})', \n",
    "                       fontsize=11, fontweight='bold')\n",
    "\n",
    "# Remove extra subplot if odd number\n",
    "if len(top_num_features) < 6:\n",
    "    fig.delaxes(axes[-1])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze categorical features (top 3)\n",
    "top_categorical = ['Neighborhood', 'OverallQual', 'ExterQual']  # Common important ones\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "for idx, cat_feature in enumerate(top_categorical):\n",
    "    if cat_feature in train_df.columns:\n",
    "        # Calculate mean price per category\n",
    "        mean_prices = train_df.groupby(cat_feature)['SalePrice'].mean().sort_values(ascending=False)\n",
    "        \n",
    "        axes[idx].barh(mean_prices.index.astype(str), mean_prices.values, color='coral')\n",
    "        axes[idx].set_xlabel('Average Sale Price ($)', fontsize=10)\n",
    "        axes[idx].set_ylabel(cat_feature, fontsize=10)\n",
    "        axes[idx].set_title(f'Average Price by {cat_feature}', fontsize=12, fontweight='bold')\n",
    "        axes[idx].invert_yaxis()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Outlier Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detect outliers using IQR method for top features\n",
    "def detect_outliers_iqr(df, feature):\n",
    "    Q1 = df[feature].quantile(0.25)\n",
    "    Q3 = df[feature].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    outliers = df[(df[feature] < lower_bound) | (df[feature] > upper_bound)]\n",
    "    return len(outliers)\n",
    "\n",
    "# Check outliers for top numerical features\n",
    "outlier_counts = {}\n",
    "for feature in top_num_features:\n",
    "    outlier_counts[feature] = detect_outliers_iqr(train_df, feature)\n",
    "\n",
    "print('Outlier counts for top features:')\n",
    "for feature, count in outlier_counts.items():\n",
    "    print(f'{feature}: {count} outliers ({count/len(train_df)*100:.1f}%)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize potential outliers in SalePrice\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# GrLivArea vs SalePrice (common outlier relationship)\n",
    "axes[0].scatter(train_df['GrLivArea'], train_df['SalePrice'], alpha=0.6)\n",
    "axes[0].set_xlabel('Above Grade Living Area (sq ft)', fontsize=11)\n",
    "axes[0].set_ylabel('Sale Price ($)', fontsize=11)\n",
    "axes[0].set_title('Living Area vs Price (Check for outliers)', fontsize=12, fontweight='bold')\n",
    "\n",
    "# TotalBsmtSF vs SalePrice\n",
    "axes[1].scatter(train_df['TotalBsmtSF'], train_df['SalePrice'], alpha=0.6, color='orange')\n",
    "axes[1].set_xlabel('Total Basement Area (sq ft)', fontsize=11)\n",
    "axes[1].set_ylabel('Sale Price ($)', fontsize=11)\n",
    "axes[1].set_title('Basement Area vs Price (Check for outliers)', fontsize=12, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print('\\nNote: Large living areas with low prices might be outliers to investigate.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Key Insights and Next Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary statistics\n",
    "print('='*60)\n",
    "print('EDA SUMMARY AND KEY INSIGHTS')\n",
    "print('='*60)\n",
    "print(f'\\n1. DATASET:')\n",
    "print(f'   - Training samples: {len(train_df)}')\n",
    "print(f'   - Features: {len(train_df.columns) - 1} (excluding target)')\n",
    "print(f'   - Numerical features: {len(numerical_features)}')\n",
    "print(f'   - Categorical features: {len(categorical_features)}')\n",
    "\n",
    "print(f'\\n2. TARGET VARIABLE (SalePrice):')\n",
    "print(f'   - Mean: ${train_df[\"SalePrice\"].mean():,.0f}')\n",
    "print(f'   - Median: ${train_df[\"SalePrice\"].median():,.0f}')\n",
    "print(f'   - Range: ${train_df[\"SalePrice\"].min():,.0f} - ${train_df[\"SalePrice\"].max():,.0f}')\n",
    "print(f'   - Skewness: {train_df[\"SalePrice\"].skew():.2f} (right-skewed)')\n",
    "print(f'   - Recommendation: Consider log transformation')\n",
    "\n",
    "print(f'\\n3. MISSING VALUES:')\n",
    "print(f'   - Features with missing data: {len(missing_df)}')\n",
    "if len(missing_df) > 0:\n",
    "    print(f'   - Worst feature: {missing_df.iloc[0][\"Feature\"]} ({missing_df.iloc[0][\"Missing_Percentage\"]:.1f}% missing)')\n",
    "print(f'   - Action: Need imputation strategy')\n",
    "\n",
    "print(f'\\n4. TOP PREDICTIVE FEATURES:')\n",
    "for i, (feature, corr) in enumerate(correlations.head(6)[1:].items(), 1):\n",
    "    print(f'   {i}. {feature}: {corr:.3f}')\n",
    "\n",
    "print(f'\\n5. NEXT STEPS (Feature Engineering):')\n",
    "print(f'   - Handle missing values (imputation)')\n",
    "print(f'   - Log-transform SalePrice and skewed features')\n",
    "print(f'   - Encode categorical variables')\n",
    "print(f'   - Remove or cap outliers')\n",
    "print(f'   - Create new features (e.g., TotalSF, Age)')\n",
    "print(f'   - Feature scaling/normalization')\n",
    "print('='*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Save EDA Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save correlation data for reference\n",
    "correlations.to_csv('../data/processed/feature_correlations.csv', header=['Correlation'])\n",
    "print('Correlation data saved to: data/processed/feature_correlations.csv')\n",
    "\n",
    "# Save missing values report\n",
    "if len(missing_df) > 0:\n",
    "    missing_df.to_csv('../data/processed/missing_values_report.csv', index=False)\n",
    "    print('Missing values report saved to: data/processed/missing_values_report.csv')\n",
    "\n",
    "print('\\nEDA Complete! Ready for Phase 3: Feature Engineering & Model Training')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
